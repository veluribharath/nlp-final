{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57962517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser, \\\n",
    "    TrainerCallback\n",
    "from transformers.trainer_utils import PredictionOutput\n",
    "from helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db17dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_training_dynamics(output_dir: os.path,\n",
    "                          epoch: int,\n",
    "                          train_ids: List[int],\n",
    "                          train_logits: List[List[float]],\n",
    "                          train_golds: List[int],\n",
    "                        dynamics_type: str = 'training'):\n",
    "    \"\"\"\n",
    "    Save training dynamics (logits) from given epoch as records of a `.jsonl` file.\n",
    "    \"\"\"\n",
    "    td_df = pd.DataFrame({\"guid\": train_ids,\n",
    "                        f\"logits_epoch_{epoch}\": train_logits,\n",
    "                        \"gold\": train_golds})\n",
    "\n",
    "    logging_dir = os.path.join(output_dir, f\"{dynamics_type}_dynamics\")\n",
    "    # Create directory for logging training dynamics, if it doesn't already exist.\n",
    "    if not os.path.exists(logging_dir):\n",
    "        os.makedirs(logging_dir)\n",
    "    epoch_file_name = os.path.join(logging_dir, f\"dynamics_epoch_{epoch}.jsonl\")\n",
    "    td_df.to_json(epoch_file_name, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae18c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ba654da727498d841c8910bd9c55e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('csv'\n",
    "                                ,data_files = {'train': 'velurib-datasets/SNLI/train.tsv'\n",
    "                                               ,'eval': 'velurib-datasets/SNLI/validation.tsv'\n",
    "                                               , 'test': 'velurib-datasets/SNLI/test.tsv'}\n",
    "                               ,delimiter='\\t')\n",
    "dataset = dataset.filter(lambda ex: isinstance(ex['hypothesis'], (str,list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20129511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../trained_model_velurib_nli_b256/checkpoint-537/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b0bc022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, **{'num_labels': 3})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282e6007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/549361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/9842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_train_dataset = prepare_eval_dataset = lambda exs: prepare_dataset_nli(exs, tokenizer, 128)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "train_remove_columns = train_dataset.column_names.remove(\"id\")\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "            prepare_train_dataset,\n",
    "            batched=True,\n",
    "            num_proc=2,\n",
    "            remove_columns=train_remove_columns\n",
    ")\n",
    "\n",
    "eval_dataset = dataset['validation']\n",
    "eval_remove_columns = eval_dataset.column_names.remove(\"id\")\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "            prepare_eval_dataset,\n",
    "            batched=True,\n",
    "            num_proc=2,\n",
    "            remove_columns=eval_remove_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23f4ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_featurized,\n",
    "    eval_dataset=eval_dataset_featurized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "296788ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_predictions = trainer.predict(test_dataset=trainer.eval_dataset, metric_key_prefix=\"eval\")\n",
    "log_training_dynamics(model_path, 0, trainer.eval_dataset['id'] , list(eval_predictions.predictions) , eval_predictions.label_ids, 'eval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe62ef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'id'],\n",
       "        num_rows: 549361\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'id'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'id'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c2c44",
   "metadata": {},
   "source": [
    "## Run on all checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efeb9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7178e9d1d89a8a55_*_of_00002.arrow\n",
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f6ea7ffa61e9957f_*_of_00002.arrow\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-921143dadab473c5_*_of_00002.arrow\n",
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-59b4c8bf5d3f4578_*_of_00002.arrow\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-80fb1dacc3f5ae66_*_of_00002.arrow\n",
      "Loading cached processed dataset at /Users/velurib/.cache/huggingface/datasets/csv/default-1cdfb178aa57f411/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a9234160ac354faf_*_of_00002.arrow\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_path in ['../trained_model_velurib_nli_b256/checkpoint-537/', \n",
    "                  '../trained_model_velurib_nli_b256/checkpoint-1074/',\n",
    "                  '../trained_model_velurib_nli_b256/checkpoint-1611/']:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, **{'num_labels': 3})\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "    prepare_train_dataset = prepare_eval_dataset = lambda exs: prepare_dataset_nli(exs, tokenizer, 128)\n",
    "\n",
    "    train_dataset = dataset['train']\n",
    "    train_remove_columns = train_dataset.column_names.remove(\"id\")\n",
    "    train_dataset_featurized = train_dataset.map(\n",
    "                prepare_train_dataset,\n",
    "                batched=True,\n",
    "                num_proc=2,\n",
    "                remove_columns=train_remove_columns\n",
    "    )\n",
    "\n",
    "    eval_dataset = dataset['eval']\n",
    "    eval_remove_columns = eval_dataset.column_names.remove(\"id\")\n",
    "    eval_dataset_featurized = eval_dataset.map(\n",
    "                prepare_eval_dataset,\n",
    "                batched=True,\n",
    "                num_proc=2,\n",
    "                remove_columns=eval_remove_columns\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset_featurized,\n",
    "        eval_dataset=eval_dataset_featurized,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_accuracy\n",
    "    )\n",
    "    eval_predictions = trainer.predict(test_dataset=trainer.eval_dataset, metric_key_prefix=\"eval\")\n",
    "    log_training_dynamics(model_path, 0, trainer.eval_dataset['id'] , list(eval_predictions.predictions) , eval_predictions.label_ids, 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cc70a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'id', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 9842\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_featurized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a370c0",
   "metadata": {},
   "source": [
    "## Calculate eval dy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6e3a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamics_epoch_1.jsonl\n",
      "dynamics_epoch_0.jsonl\n",
      "dynamics_epoch_2.jsonl\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('../trained_model_velurib_nli_b256/eval_dynamics/'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "522e16eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>logits_epoch_0</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.7553514242000001, 2.859858036, -1.0490977764]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2.7545409203, -1.1148138046, -2.2792580128]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.521065712, -1.3992186785, 3.3681161404]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.1913676262, -0.8820856214, -1.7921061516]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-2.4113121033000002, 1.7274105549, 0.59841269...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>9837</td>\n",
       "      <td>[2.2715210915, -0.1293645054, -2.5752403736]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>9838</td>\n",
       "      <td>[0.374204278, 0.4493592978, -0.8702021241000001]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>9839</td>\n",
       "      <td>[2.5805034637, -0.7992218137, -2.3387358189]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>9840</td>\n",
       "      <td>[-2.3287031651, -0.6759002805000001, 2.6303536...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>9841</td>\n",
       "      <td>[-1.5582636595000001, 2.4880461693, -0.8241568...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      guid                                     logits_epoch_0  gold\n",
       "0        0  [-1.7553514242000001, 2.859858036, -1.0490977764]     1\n",
       "1        1       [2.7545409203, -1.1148138046, -2.2792580128]     0\n",
       "2        2        [-2.521065712, -1.3992186785, 3.3681161404]     2\n",
       "3        3       [2.1913676262, -0.8820856214, -1.7921061516]     0\n",
       "4        4  [-2.4113121033000002, 1.7274105549, 0.59841269...     1\n",
       "...    ...                                                ...   ...\n",
       "9837  9837       [2.2715210915, -0.1293645054, -2.5752403736]     0\n",
       "9838  9838   [0.374204278, 0.4493592978, -0.8702021241000001]     2\n",
       "9839  9839       [2.5805034637, -0.7992218137, -2.3387358189]     0\n",
       "9840  9840  [-2.3287031651, -0.6759002805000001, 2.6303536...     2\n",
       "9841  9841  [-1.5582636595000001, 2.4880461693, -0.8241568...     1\n",
       "\n",
       "[9842 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0 = pd.read_json('../trained_model_velurib_nli_b256/eval_dynamics/dynamics_epoch_0.jsonl',lines=True)\n",
    "temp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0aca5d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>logits_epoch_1</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.5230602026, 3.2023732662, -1.6116229296]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2.8523051739, -1.1013753414, -2.4134397507]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.7888793945, -1.7099151611, 3.8191409111]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.1382279396, -0.7769355178, -1.8178160191000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-2.3382945061, 2.2766933441, 0.029231986]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>9837</td>\n",
       "      <td>[2.3841061592, 0.1701157242, -2.9601159096]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>9838</td>\n",
       "      <td>[1.0663279295, 0.44765171410000004, -1.6633120...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>9839</td>\n",
       "      <td>[2.7649593353, -0.835172534, -2.5396065712]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>9840</td>\n",
       "      <td>[-2.5751872063, -1.2368717194, 3.285118103]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>9841</td>\n",
       "      <td>[-1.4254318476, 2.8950486183, -1.35400033]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      guid                                     logits_epoch_1  gold\n",
       "0        0       [-1.5230602026, 3.2023732662, -1.6116229296]     1\n",
       "1        1       [2.8523051739, -1.1013753414, -2.4134397507]     0\n",
       "2        2       [-2.7888793945, -1.7099151611, 3.8191409111]     2\n",
       "3        3  [2.1382279396, -0.7769355178, -1.8178160191000...     0\n",
       "4        4         [-2.3382945061, 2.2766933441, 0.029231986]     1\n",
       "...    ...                                                ...   ...\n",
       "9837  9837        [2.3841061592, 0.1701157242, -2.9601159096]     0\n",
       "9838  9838  [1.0663279295, 0.44765171410000004, -1.6633120...     2\n",
       "9839  9839        [2.7649593353, -0.835172534, -2.5396065712]     0\n",
       "9840  9840        [-2.5751872063, -1.2368717194, 3.285118103]     2\n",
       "9841  9841         [-1.4254318476, 2.8950486183, -1.35400033]     1\n",
       "\n",
       "[9842 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = pd.read_json('../trained_model_velurib_nli_b256/eval_dynamics/dynamics_epoch_1.jsonl',lines=True)\n",
    "temp1.rename(columns = {'logits_epoch_0':'logits_epoch_1'},inplace=True)\n",
    "temp1.to_json('../trained_model_velurib_nli_b256/eval_dynamics/dynamics_epoch_1.jsonl',orient='records',lines=True)\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bceb443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>logits_epoch_2</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.6128150225, 3.3128418922, -1.6511343718]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2.7326819897, -1.083240509, -2.2756221294]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.8974208832, -1.7878544331, 3.9609210491]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.1518702507, -0.7173354030000001, -1.8891099...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-2.2169373035, 2.4191398621, -0.2217153907000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>9837</td>\n",
       "      <td>[2.2063443661, 0.4153587818, -2.9541020393]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>9838</td>\n",
       "      <td>[0.9539057612, 0.5845272541000001, -1.65183806...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>9839</td>\n",
       "      <td>[2.7053320408, -0.7923318744000001, -2.5022206...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>9840</td>\n",
       "      <td>[-2.5661716461, -1.2289872169, 3.2687718868]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>9841</td>\n",
       "      <td>[-1.5127729177, 3.0462267399, -1.4396331310000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      guid                                     logits_epoch_2  gold\n",
       "0        0       [-1.6128150225, 3.3128418922, -1.6511343718]     1\n",
       "1        1        [2.7326819897, -1.083240509, -2.2756221294]     0\n",
       "2        2       [-2.8974208832, -1.7878544331, 3.9609210491]     2\n",
       "3        3  [2.1518702507, -0.7173354030000001, -1.8891099...     0\n",
       "4        4  [-2.2169373035, 2.4191398621, -0.2217153907000...     1\n",
       "...    ...                                                ...   ...\n",
       "9837  9837        [2.2063443661, 0.4153587818, -2.9541020393]     0\n",
       "9838  9838  [0.9539057612, 0.5845272541000001, -1.65183806...     2\n",
       "9839  9839  [2.7053320408, -0.7923318744000001, -2.5022206...     0\n",
       "9840  9840       [-2.5661716461, -1.2289872169, 3.2687718868]     2\n",
       "9841  9841  [-1.5127729177, 3.0462267399, -1.4396331310000...     1\n",
       "\n",
       "[9842 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = pd.read_json('../trained_model_velurib_nli_b256/eval_dynamics/dynamics_epoch_2.jsonl',lines=True)\n",
    "temp2.rename(columns = {'logits_epoch_0':'logits_epoch_2'},inplace=True)\n",
    "temp2.to_json('../trained_model_velurib_nli_b256/eval_dynamics/dynamics_epoch_2.jsonl',orient='records',lines=True)\n",
    "temp2.to_json\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
